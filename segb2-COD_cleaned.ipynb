{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T12:31:17.044107Z",
     "iopub.status.busy": "2025-04-20T12:31:17.043860Z",
     "iopub.status.idle": "2025-04-20T15:37:56.805658Z",
     "shell.execute_reply": "2025-04-20T15:37:56.804210Z",
     "shell.execute_reply.started": "2025-04-20T12:31:17.044086Z"
    }
   },
   "outputs": [],
   "source": [
    "# ‚úÖ Step 1: Install packages\n",
    "!pip install -q transformers accelerate albumentations\n",
    "\n",
    "# ‚úÖ Step 2: Imports\n",
    "import os, cv2, numpy as np, torch, torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ‚úÖ Step 3: Paths\n",
    "IMG_DIR = \"/kaggle/input/cod10k/COD10K-v3/Train/Image\"\n",
    "MASK_DIR = \"/kaggle/input/cod10k/COD10K-v3/Train/GT_Object\"\n",
    "\n",
    "# ‚úÖ Step 4: Dataset\n",
    "class COD10KDataset(Dataset):\n",
    "    def __init__(self, img_paths, mask_paths, image_size=512, augment=True):\n",
    "        self.img_paths = img_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = A.Compose([\n",
    "            A.Resize(image_size, image_size),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.ColorJitter(p=0.2),\n",
    "            A.RandomBrightnessContrast(p=0.2),\n",
    "            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "            A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "            ToTensorV2()\n",
    "        ]) if augment else A.Compose([\n",
    "            A.Resize(image_size, image_size),\n",
    "            A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n",
    "    def __len__(self): return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.img_paths[idx])\n",
    "        mask = cv2.imread(self.mask_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        mask = (mask > 0).astype(np.float32)\n",
    "        transformed = self.transform(image=image, mask=mask)\n",
    "        return {\n",
    "            'pixel_values': transformed['image'],\n",
    "            'labels': transformed['mask'].unsqueeze(0)\n",
    "        }\n",
    "\n",
    "# ‚úÖ Step 5: Data Loaders\n",
    "all_images = sorted([os.path.join(IMG_DIR, x) for x in os.listdir(IMG_DIR)])\n",
    "all_masks = sorted([os.path.join(MASK_DIR, x) for x in os.listdir(MASK_DIR)])\n",
    "train_imgs, val_imgs, train_masks, val_masks = train_test_split(all_images, all_masks, test_size=0.2, random_state=42)\n",
    "train_dataset = COD10KDataset(train_imgs, train_masks, augment=True)\n",
    "val_dataset = COD10KDataset(val_imgs, val_masks, augment=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, num_workers=2)\n",
    "\n",
    "# ‚úÖ Step 6: Model\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    \"nvidia/segformer-b2-finetuned-ade-512-512\",\n",
    "    num_labels=1,\n",
    "    ignore_mismatched_sizes=True\n",
    ").to(device)\n",
    "\n",
    "# ‚úÖ Step 7: Loss\n",
    "class MixedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.7, beta=0.3):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.alpha, self.beta = alpha, beta\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "        bce = self.bce(inputs, targets)\n",
    "        TP = (inputs * targets).sum()\n",
    "        FP = (inputs * (1 - targets)).sum()\n",
    "        FN = ((1 - inputs) * targets).sum()\n",
    "        tversky = (TP + 1e-7) / (TP + self.alpha * FP + self.beta * FN + 1e-7)\n",
    "        dice = (2 * TP + 1e-7) / (inputs.sum() + targets.sum() + 1e-7)\n",
    "        return bce + (1 - tversky) + (1 - dice)\n",
    "\n",
    "criterion = MixedLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=15)\n",
    "\n",
    "# ‚úÖ Step 8: Evaluation Metrics\n",
    "def compute_metrics(pred, mask):\n",
    "    pred = (pred > 0.5).float()\n",
    "    intersection = (pred * mask).sum((1, 2, 3))\n",
    "    union = pred.sum((1, 2, 3)) + mask.sum((1, 2, 3)) - intersection\n",
    "    iou = (intersection + 1e-7) / (union + 1e-7)\n",
    "    dice = (2 * intersection + 1e-7) / (pred.sum((1, 2, 3)) + mask.sum((1, 2, 3)) + 1e-7)\n",
    "    precision = (intersection + 1e-7) / (pred.sum((1, 2, 3)) + 1e-7)\n",
    "    recall = (intersection + 1e-7) / (mask.sum((1, 2, 3)) + 1e-7)\n",
    "    f_beta = (1.25 * precision * recall + 1e-7) / (0.25 * precision + recall + 1e-7)\n",
    "    mae = torch.abs(pred - mask).mean((1, 2, 3))\n",
    "    sm = (iou + dice) / 2\n",
    "    e = 1 - ((pred - mask) ** 2).mean((1, 2, 3))\n",
    "    return {\n",
    "        'iou': iou.mean().item(),\n",
    "        'dice': dice.mean().item(),\n",
    "        'precision': precision.mean().item(),\n",
    "        'recall': recall.mean().item(),\n",
    "        'f_beta': f_beta.mean().item(),\n",
    "        'mae': mae.mean().item(),\n",
    "        's_measure': sm.mean().item(),\n",
    "        'e_measure': e.mean().item()\n",
    "    }\n",
    "\n",
    "# ‚úÖ Step 9: Train Function (AMP + Cosine + Clip)\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, epochs=20):\n",
    "    best_s = 0\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train(); total_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\"):\n",
    "            imgs = batch[\"pixel_values\"].to(device)\n",
    "            masks = batch[\"labels\"].to(device)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(pixel_values=imgs).logits\n",
    "                outputs = torch.nn.functional.interpolate(outputs, size=masks.shape[-2:], mode=\"bilinear\")\n",
    "                loss = criterion(outputs, masks)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Train Loss: {total_loss / len(train_loader):.4f}\")\n",
    "        scheduler.step()\n",
    "\n",
    "        # ‚úÖ Validation\n",
    "        model.eval(); val_loss = 0\n",
    "        metrics = {k: [] for k in ['iou', 'dice', 'precision', 'recall', 'f_beta', 'mae', 's_measure', 'e_measure']}\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} Validation\"):\n",
    "                imgs = batch[\"pixel_values\"].to(device)\n",
    "                masks = batch[\"labels\"].to(device)\n",
    "                outputs = model(pixel_values=imgs).logits\n",
    "                outputs = torch.nn.functional.interpolate(outputs, size=masks.shape[-2:], mode=\"bilinear\")\n",
    "                loss = criterion(outputs, masks)\n",
    "                val_loss += loss.item()\n",
    "                pred = torch.sigmoid(outputs)\n",
    "                m = compute_metrics(pred, masks)\n",
    "                for k in metrics: metrics[k].append(m[k])\n",
    "\n",
    "        print(f\"üìä Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "        print(f\"üìà IoU: {np.mean(metrics['iou']):.4f}, Dice: {np.mean(metrics['dice']):.4f}, \"\n",
    "              f\"Precision: {np.mean(metrics['precision']):.4f}, Recall: {np.mean(metrics['recall']):.4f}\")\n",
    "        print(f\"‚≠ê FŒ≤: {np.mean(metrics['f_beta']):.4f}, MAE: {np.mean(metrics['mae']):.4f}, \"\n",
    "              f\"S-measure: {np.mean(metrics['s_measure']):.4f}, E-measure: {np.mean(metrics['e_measure']):.4f}\\n\")\n",
    "\n",
    "        if np.mean(metrics['s_measure']) > best_s:\n",
    "            best_s = np.mean(metrics['s_measure'])\n",
    "            torch.save(model.state_dict(), \"/kaggle/working/best_segformer_cod_smeasure.pth\")\n",
    "            print(f\"‚úÖ Best model saved (S-measure: {best_s:.4f})\\n\")\n",
    "\n",
    "# ‚úÖ Step 10: Start Training\n",
    "train(model, train_loader, val_loader, criterion, optimizer, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:42:22.920623Z",
     "iopub.status.busy": "2025-04-20T15:42:22.920308Z",
     "iopub.status.idle": "2025-04-20T15:45:47.812784Z",
     "shell.execute_reply": "2025-04-20T15:45:47.811999Z",
     "shell.execute_reply.started": "2025-04-20T15:42:22.920593Z"
    }
   },
   "outputs": [],
   "source": [
    "def final_evaluation(model, loader, name=\"Dataset\"):\n",
    "    model.eval()\n",
    "    metrics = {k: [] for k in ['iou', 'dice', 'precision', 'recall', 'f_beta', 'mae', 's_measure', 'e_measure']}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=f\"Evaluating on {name}\"):\n",
    "            imgs = batch[\"pixel_values\"].to(device)\n",
    "            masks = batch[\"labels\"].to(device)\n",
    "            outputs = model(pixel_values=imgs).logits\n",
    "            outputs = torch.nn.functional.interpolate(outputs, size=masks.shape[-2:], mode=\"bilinear\")\n",
    "            preds = torch.sigmoid(outputs)\n",
    "\n",
    "            m = compute_metrics(preds, masks)\n",
    "            for k in metrics:\n",
    "                metrics[k].append(m[k])\n",
    "\n",
    "    print(f\"\\nüìä Final {name} Metrics:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k.upper():<12}: {np.mean(v):.4f}\")\n",
    "\n",
    "# ‚úÖ Load best model weights (optional if already loaded)\n",
    "model.load_state_dict(torch.load(\"/kaggle/working/best_segformer_cod_smeasure.pth\"))\n",
    "\n",
    "# ‚úÖ Evaluate on Training and Validation sets\n",
    "final_evaluation(model, train_loader, name=\"Training Set\")\n",
    "final_evaluation(model, val_loader, name=\"Validation Set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:46:43.719271Z",
     "iopub.status.busy": "2025-04-20T15:46:43.718442Z",
     "iopub.status.idle": "2025-04-20T15:46:48.581616Z",
     "shell.execute_reply": "2025-04-20T15:46:48.580913Z",
     "shell.execute_reply.started": "2025-04-20T15:46:43.719237Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_predictions(model, dataset, num_samples=5, title=\"Visualization\"):\n",
    "    model.eval()\n",
    "    shown = 0\n",
    "    idx = 0\n",
    "\n",
    "    while shown < num_samples and idx < len(dataset):\n",
    "        sample = dataset[idx]\n",
    "        image_tensor = sample['pixel_values']\n",
    "        gt_mask = sample['labels'].squeeze().numpy()\n",
    "\n",
    "        # Skip if mask is empty (no ground truth)\n",
    "        if np.sum(gt_mask) == 0:\n",
    "            idx += 1\n",
    "            continue\n",
    "\n",
    "        with torch.no_grad():\n",
    "            image = image_tensor.unsqueeze(0).to(device)\n",
    "            output = model(pixel_values=image).logits\n",
    "            output = torch.nn.functional.interpolate(output, size=gt_mask.shape, mode=\"bilinear\", align_corners=False)\n",
    "            pred_mask = torch.sigmoid(output).squeeze().cpu().numpy()\n",
    "            pred_bin = (pred_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "        # Undo normalization for visualization\n",
    "        image_np = image_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "        if image_np.shape[2] == 1:  # grayscale fallback\n",
    "            image_np = np.repeat(image_np, 3, axis=2)\n",
    "        image_np = (image_np * 0.5 + 0.5).clip(0, 1)\n",
    "\n",
    "        # Plot\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        axs[0].imshow(image_np)\n",
    "        axs[0].set_title(\"Input Image\")\n",
    "        axs[1].imshow(gt_mask, cmap='gray')\n",
    "        axs[1].set_title(\"Ground Truth\")\n",
    "        axs[2].imshow(pred_bin, cmap='gray')\n",
    "        axs[2].set_title(\"Predicted Mask\")\n",
    "        for ax in axs:\n",
    "            ax.axis('off')\n",
    "        plt.suptitle(f\"{title} Example #{shown + 1}\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        shown += 1\n",
    "        idx += 1\n",
    "# Visualize training predictions\n",
    "visualize_predictions(model, train_dataset, num_samples=5, title=\"Training\")\n",
    "\n",
    "# Visualize validation predictions\n",
    "visualize_predictions(model, val_dataset, num_samples=5, title=\"Validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:48:33.475212Z",
     "iopub.status.busy": "2025-04-20T15:48:33.474911Z",
     "iopub.status.idle": "2025-04-20T15:48:33.492446Z",
     "shell.execute_reply": "2025-04-20T15:48:33.491854Z",
     "shell.execute_reply.started": "2025-04-20T15:48:33.475189Z"
    }
   },
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è Set your correct test image and mask paths\n",
    "TEST_IMG_DIR = \"/kaggle/input/cod10k/COD10K-v3/Test/Image\"\n",
    "TEST_MASK_DIR = \"/kaggle/input/cod10k/COD10K-v3/Test/GT_Object\"\n",
    "\n",
    "test_images = sorted([os.path.join(TEST_IMG_DIR, x) for x in os.listdir(TEST_IMG_DIR)])\n",
    "test_masks = sorted([os.path.join(TEST_MASK_DIR, x) for x in os.listdir(TEST_MASK_DIR)])\n",
    "\n",
    "test_dataset = COD10KDataset(test_images, test_masks, augment=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:48:53.439690Z",
     "iopub.status.busy": "2025-04-20T15:48:53.439419Z",
     "iopub.status.idle": "2025-04-20T15:48:53.585864Z",
     "shell.execute_reply": "2025-04-20T15:48:53.585127Z",
     "shell.execute_reply.started": "2025-04-20T15:48:53.439669Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the best weights (make sure path is correct)\n",
    "model.load_state_dict(torch.load(\"/kaggle/working/best_segformer_cod_smeasure.pth\"))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:49:24.812725Z",
     "iopub.status.busy": "2025-04-20T15:49:24.811871Z",
     "iopub.status.idle": "2025-04-20T15:51:41.121706Z",
     "shell.execute_reply": "2025-04-20T15:51:41.120845Z",
     "shell.execute_reply.started": "2025-04-20T15:49:24.812631Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader, name=\"Test Set\"):\n",
    "    model.eval()\n",
    "    metrics = {k: [] for k in ['iou', 'dice', 'precision', 'recall', 'f_beta', 'mae', 's_measure', 'e_measure']}\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=f\"Evaluating on {name}\"):\n",
    "            imgs = batch[\"pixel_values\"].to(device)\n",
    "            masks = batch[\"labels\"].to(device)\n",
    "            outputs = model(pixel_values=imgs).logits\n",
    "            outputs = torch.nn.functional.interpolate(outputs, size=masks.shape[-2:], mode=\"bilinear\")\n",
    "            pred = torch.sigmoid(outputs)\n",
    "            m = compute_metrics(pred, masks)\n",
    "            for k in metrics: metrics[k].append(m[k])\n",
    "\n",
    "    print(f\"\\nüìä Final {name} Metrics:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k.upper():<12}: {np.mean(v):.4f}\")\n",
    "evaluate_model(model, test_loader, name=\"Test Set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:52:45.785748Z",
     "iopub.status.busy": "2025-04-20T15:52:45.785426Z",
     "iopub.status.idle": "2025-04-20T15:52:48.534482Z",
     "shell.execute_reply": "2025-04-20T15:52:48.533708Z",
     "shell.execute_reply.started": "2025-04-20T15:52:45.785720Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_test_predictions(model, dataset, num_samples=5):\n",
    "    model.eval()\n",
    "    shown = 0\n",
    "    idx = 0\n",
    "\n",
    "    while shown < num_samples and idx < len(dataset):\n",
    "        sample = dataset[idx]\n",
    "        image = sample['pixel_values'].unsqueeze(0).to(device)\n",
    "        gt_mask = sample['labels'].squeeze().cpu().numpy()\n",
    "\n",
    "        if np.sum(gt_mask) == 0:\n",
    "            idx += 1\n",
    "            continue\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(pixel_values=image).logits\n",
    "            output = torch.nn.functional.interpolate(output, size=gt_mask.shape, mode=\"bilinear\", align_corners=False)\n",
    "            pred_mask = torch.sigmoid(output).squeeze().cpu().numpy()\n",
    "            pred_bin = (pred_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "        # üñºÔ∏è Denormalize image for display\n",
    "        image_vis = image.squeeze().cpu().permute(1, 2, 0).numpy()\n",
    "        image_vis = (image_vis * 0.5 + 0.5).clip(0, 1)  # undo normalization\n",
    "\n",
    "        # üìä Plot\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        axs[0].imshow(image_vis)\n",
    "        axs[0].set_title('Input Image')\n",
    "        axs[1].imshow(gt_mask, cmap='gray')\n",
    "        axs[1].set_title('Ground Truth')\n",
    "        axs[2].imshow(pred_bin, cmap='gray')\n",
    "        axs[2].set_title('Predicted Mask')\n",
    "        for ax in axs: ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        shown += 1\n",
    "        idx += 1\n",
    "visualize_test_predictions(model, test_dataset, num_samples=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:54:58.704169Z",
     "iopub.status.busy": "2025-04-20T15:54:58.703845Z",
     "iopub.status.idle": "2025-04-20T15:55:08.822463Z",
     "shell.execute_reply": "2025-04-20T15:55:08.821667Z",
     "shell.execute_reply.started": "2025-04-20T15:54:58.704132Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_predictions(model, dataset, num_samples=5, start_idx=0, dataset_name=\"Set\"):\n",
    "    model.eval()\n",
    "    shown = 0\n",
    "    idx = start_idx\n",
    "\n",
    "    while shown < num_samples and idx < len(dataset):\n",
    "        sample = dataset[idx]\n",
    "        image = sample['pixel_values'].unsqueeze(0).to(device)\n",
    "        gt_mask = sample['labels'].squeeze().cpu().numpy()\n",
    "\n",
    "        if np.sum(gt_mask) == 0:\n",
    "            idx += 1\n",
    "            continue\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(pixel_values=image).logits\n",
    "            output = torch.nn.functional.interpolate(output, size=gt_mask.shape, mode=\"bilinear\", align_corners=False)\n",
    "            pred_mask = torch.sigmoid(output).squeeze().cpu().numpy()\n",
    "            pred_mask_bin = (pred_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "        input_image = image.squeeze().cpu().permute(1, 2, 0).numpy()\n",
    "        input_image = (input_image * 0.5 + 0.5).clip(0, 1)\n",
    "\n",
    "        # Plot\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(16, 5))\n",
    "        axs[0].imshow(input_image)\n",
    "        axs[0].set_title(f'{dataset_name} - Input Image')\n",
    "        axs[1].imshow(gt_mask, cmap='gray')\n",
    "        axs[1].set_title('Ground Truth')\n",
    "        axs[2].imshow(pred_mask_bin, cmap='gray')\n",
    "        axs[2].set_title('Predicted Mask')\n",
    "        for ax in axs:\n",
    "            ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        shown += 1\n",
    "        idx += 1\n",
    "\n",
    "    return idx  # return updated start index\n",
    "# üîç Train Set Visualization in batches\n",
    "train_index = 0\n",
    "train_index = visualize_predictions(model, train_dataset, num_samples=5, start_idx=train_index, dataset_name=\"Train\")\n",
    "train_index = visualize_predictions(model, train_dataset, num_samples=5, start_idx=train_index, dataset_name=\"Train\")\n",
    "\n",
    "# üîç Validation Set\n",
    "val_index = 0\n",
    "val_index = visualize_predictions(model, val_dataset, num_samples=5, start_idx=val_index, dataset_name=\"Validation\")\n",
    "\n",
    "# üîç Test Set\n",
    "test_index = 0\n",
    "test_dataset = COD10KDataset(test_images, test_masks, augment=False)\n",
    "test_index = visualize_predictions(model, test_dataset, num_samples=5, start_idx=test_index, dataset_name=\"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:02:51.311136Z",
     "iopub.status.busy": "2025-04-20T16:02:51.310386Z",
     "iopub.status.idle": "2025-04-20T16:02:56.436569Z",
     "shell.execute_reply": "2025-04-20T16:02:56.435611Z",
     "shell.execute_reply.started": "2025-04-20T16:02:51.311108Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "def visualize_loader(loader, model, device, num_examples=5, thresh=0.5, title_prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Shows up to `num_examples` valid (non‚Äëempty GT & non‚Äëempty pred) samples from `loader`.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    shown = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            imgs = batch[\"pixel_values\"].to(device)      # [B,3,H,W]\n",
    "            gts  = batch[\"labels\"].to(device)            # [B,1,H,W]\n",
    "            logits = model(pixel_values=imgs).logits     # [B,1,H,W]\n",
    "            probs  = torch.sigmoid(logits)               # [B,1,H,W]\n",
    "\n",
    "            B = imgs.size(0)\n",
    "            for i in range(B):\n",
    "                gt_mask   = gts[i,0].cpu().numpy()\n",
    "                if gt_mask.sum() == 0:\n",
    "                    continue    # no GT, skip\n",
    "\n",
    "                pred_prob = probs[i,0].cpu().numpy()\n",
    "                pred_bin  = (pred_prob > thresh).astype(np.uint8)\n",
    "                if pred_bin.sum() == 0:\n",
    "                    continue    # empty prediction, skip\n",
    "\n",
    "                # Plot\n",
    "                fig, ax = plt.subplots(1,3,figsize=(12,4))\n",
    "                ax[0].imshow(to_pil_image(imgs[i].cpu()))\n",
    "                ax[0].set_title(f\"{title_prefix} Image\")\n",
    "                ax[1].imshow(gt_mask,   cmap=\"gray\")\n",
    "                ax[1].set_title(\"Ground Truth\")\n",
    "                ax[2].imshow(pred_bin,  cmap=\"gray\")\n",
    "                ax[2].set_title(\"Predicted Mask\")\n",
    "                for a in ax: a.axis(\"off\")\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "                shown += 1\n",
    "                if shown >= num_examples:\n",
    "                    return\n",
    "\n",
    "    if shown == 0:\n",
    "        print(\"‚ö†Ô∏è  No valid examples to show (all GT or preds empty).\")\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "visualize_loader(train_loader, model, device, num_examples=3, thresh=0.5, title_prefix=\"Train\")\n",
    "visualize_loader(val_loader,   model, device, num_examples=3, thresh=0.5, title_prefix=\"Val\")\n",
    "visualize_loader(test_loader,  model, device, num_examples=3, thresh=0.5, title_prefix=\"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:06:29.353023Z",
     "iopub.status.busy": "2025-04-20T16:06:29.352713Z",
     "iopub.status.idle": "2025-04-20T16:06:29.529973Z",
     "shell.execute_reply": "2025-04-20T16:06:29.529083Z",
     "shell.execute_reply.started": "2025-04-20T16:06:29.352996Z"
    }
   },
   "outputs": [],
   "source": [
    "!cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:06:47.032540Z",
     "iopub.status.busy": "2025-04-20T16:06:47.031850Z",
     "iopub.status.idle": "2025-04-20T16:06:47.212225Z",
     "shell.execute_reply": "2025-04-20T16:06:47.211420Z",
     "shell.execute_reply.started": "2025-04-20T16:06:47.032512Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:09:22.808896Z",
     "iopub.status.busy": "2025-04-20T16:09:22.808049Z",
     "iopub.status.idle": "2025-04-20T16:09:22.988708Z",
     "shell.execute_reply": "2025-04-20T16:09:22.987805Z",
     "shell.execute_reply.started": "2025-04-20T16:09:22.808867Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls\n",
    "\n",
    "from IPython.display import FileLink\n",
    "FileLink('best_segformer_cod_smeasure.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:11:51.358295Z",
     "iopub.status.busy": "2025-04-20T16:11:51.357567Z",
     "iopub.status.idle": "2025-04-20T16:11:56.261572Z",
     "shell.execute_reply": "2025-04-20T16:11:56.260817Z",
     "shell.execute_reply.started": "2025-04-20T16:11:51.358264Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_examples(loader, model, device, num_examples=5, split_name=\"Split\", thresh=0.5):\n",
    "    model.eval()\n",
    "    shown = 0\n",
    "    # we‚Äôll fix a random order so you don‚Äôt always see the same first few images\n",
    "    indices = list(range(len(loader.dataset)))\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    for idx in indices:\n",
    "        img_tensor, gt_mask = loader.dataset[idx]['pixel_values'], loader.dataset[idx]['labels']\n",
    "        # skip empty GT\n",
    "        if gt_mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        # run it through the model\n",
    "        with torch.no_grad():\n",
    "            inp = img_tensor.unsqueeze(0).to(device)\n",
    "            logits = model(pixel_values=inp).logits\n",
    "            pred_prob = torch.sigmoid(\n",
    "                torch.nn.functional.interpolate(\n",
    "                    logits, size=gt_mask.shape[-2:], mode=\"bilinear\", align_corners=False\n",
    "                )\n",
    "            ).squeeze(0).cpu()\n",
    "        pred_mask = (pred_prob > thresh).float()\n",
    "\n",
    "        # prepare visuals\n",
    "        img = img_tensor.permute(1,2,0).cpu().numpy()  # C,H,W -> H,W,C\n",
    "        img = (img*0.5 + 0.5).clip(0,1)                 # un-normalize\n",
    "        gt  = gt_mask.squeeze(0).cpu().numpy()\n",
    "        pm  = pred_mask.squeeze(0).numpy()\n",
    "\n",
    "        # overlay: red = GT, green = PRED\n",
    "        overlay = img.copy()\n",
    "        overlay[gt>0,   0] = 1.0   # red channel\n",
    "        overlay[pm>0,   1] = 1.0   # green channel\n",
    "\n",
    "        # plot\n",
    "        fig, axes = plt.subplots(1,4, figsize=(16,4))\n",
    "        axes[0].imshow(img);       axes[0].set_title(f\"{split_name}\\nInput\");      axes[0].axis('off')\n",
    "        axes[1].imshow(gt,  cmap='gray'); axes[1].set_title(\"GT mask\");                axes[1].axis('off')\n",
    "        axes[2].imshow(pm,  cmap='gray'); axes[2].set_title(\"Pred mask\");              axes[2].axis('off')\n",
    "        axes[3].imshow(overlay);    axes[3].set_title(\"Overlay (R=GT, G=Pred)\"); axes[3].axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        shown += 1\n",
    "        if shown >= num_examples:\n",
    "            break\n",
    "\n",
    "# Usage ‚Äî call once per split:\n",
    "visualize_examples(train_loader, model, device, num_examples=3, split_name=\"Train\")\n",
    "visualize_examples(val_loader,   model, device, num_examples=3, split_name=\"Val\")\n",
    "visualize_examples(test_loader,  model, device, num_examples=3, split_name=\"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:19:47.898579Z",
     "iopub.status.busy": "2025-04-20T16:19:47.898274Z",
     "iopub.status.idle": "2025-04-20T16:19:53.477311Z",
     "shell.execute_reply": "2025-04-20T16:19:53.476514Z",
     "shell.execute_reply.started": "2025-04-20T16:19:47.898561Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_examples(loader, model, device, num_examples=5, split_name=\"Split\", thresh=0.5):\n",
    "    model.eval()\n",
    "    shown = 0\n",
    "    # we‚Äôll fix a random order so you don‚Äôt always see the same first few images\n",
    "    indices = list(range(len(loader.dataset)))\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    for idx in indices:\n",
    "        img_tensor, gt_mask = loader.dataset[idx]['pixel_values'], loader.dataset[idx]['labels']\n",
    "        if gt_mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        # run it through the model\n",
    "        with torch.no_grad():\n",
    "            inp = img_tensor.unsqueeze(0).to(device)\n",
    "            logits = model(pixel_values=inp).logits\n",
    "            pred_prob = torch.sigmoid(\n",
    "                torch.nn.functional.interpolate(\n",
    "                    logits, size=gt_mask.shape[-2:], mode=\"bilinear\", align_corners=False\n",
    "                )\n",
    "            ).squeeze(0).cpu()\n",
    "        pred_mask = (pred_prob > thresh).float()\n",
    "\n",
    "        # prepare visuals\n",
    "        img = img_tensor.permute(1,2,0).cpu().numpy()  # C,H,W -> H,W,C\n",
    "        img = (img*0.5 + 0.5).clip(0,1)                 # un-normalize\n",
    "        gt  = gt_mask.squeeze(0).cpu().numpy()\n",
    "        pm  = pred_mask.squeeze(0).numpy()\n",
    "\n",
    "        # overlay: red = GT, green = PRED\n",
    "        overlay = img.copy()\n",
    "        overlay[gt>0,   0] = 1.0   # red channel\n",
    "        overlay[pm>0,   1] = 1.0   # green channel\n",
    "\n",
    "        # plot\n",
    "        fig, axes = plt.subplots(1,4, figsize=(16,4))\n",
    "        axes[0].imshow(img);       axes[0].set_title(f\"{split_name}\\nInput\");      axes[0].axis('off')\n",
    "        axes[1].imshow(gt,  cmap='gray'); axes[1].set_title(\"GT mask\");                axes[1].axis('off')\n",
    "        axes[2].imshow(pm,  cmap='gray'); axes[2].set_title(\"Pred mask\");              axes[2].axis('off')\n",
    "        axes[3].imshow(overlay);    axes[3].set_title(\"Overlay (R=GT, G=Pred)\"); axes[3].axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        shown += 1\n",
    "        if shown >= num_examples:\n",
    "            break\n",
    "\n",
    "# Usage ‚Äî call once per split:\n",
    "visualize_examples(train_loader, model, device, num_examples=3, split_name=\"Train\")\n",
    "visualize_examples(val_loader,   model, device, num_examples=3, split_name=\"Val\")\n",
    "visualize_examples(test_loader,  model, device, num_examples=3, split_name=\"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T17:11:28.600285Z",
     "iopub.status.busy": "2025-04-20T17:11:28.599548Z",
     "iopub.status.idle": "2025-04-20T17:11:28.696565Z",
     "shell.execute_reply": "2025-04-20T17:11:28.695973Z",
     "shell.execute_reply.started": "2025-04-20T17:11:28.600259Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Define transform (use same as training)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "image_dir = \"/kaggle/input/nc4kdataset/Imgs\"\n",
    "gt_dir = \"/kaggle/input/nc4kdataset/GT\"\n",
    "\n",
    "image_files = sorted(os.listdir(image_dir))\n",
    "gt_files = sorted(os.listdir(gt_dir))\n",
    "\n",
    "def load_image(path):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    return transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "def load_mask(path):\n",
    "    mask = Image.open(path).convert(\"L\")\n",
    "    return transforms.Resize((512, 512))(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T17:15:47.428980Z",
     "iopub.status.busy": "2025-04-20T17:15:47.428696Z",
     "iopub.status.idle": "2025-04-20T17:16:29.753380Z",
     "shell.execute_reply": "2025-04-20T17:16:29.752455Z",
     "shell.execute_reply.started": "2025-04-20T17:15:47.428956Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2  # Import OpenCV for resizing\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the Dice score function\n",
    "def dice_score(pred, gt):\n",
    "    intersection = np.sum(pred * gt)\n",
    "    return 2.0 * intersection / (np.sum(pred) + np.sum(gt) + 1e-7)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "def predict_and_evaluate():\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    dice_list = []\n",
    "\n",
    "    for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        imgs = batch[\"pixel_values\"].to(device)\n",
    "        gt_masks = batch[\"labels\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(imgs)  # Model returns a SemanticSegmenterOutput\n",
    "            pred_mask = torch.sigmoid(pred.logits).squeeze().cpu().numpy() > 0.5  # Access logits\n",
    "            gt_mask = gt_masks.squeeze().cpu().numpy() > 0.5  # Convert to binary mask\n",
    "\n",
    "        # Convert gt_mask to uint8 for resizing\n",
    "        gt_mask_uint8 = (gt_mask * 255).astype(np.uint8)\n",
    "\n",
    "        # Resize ground truth masks to match the predicted mask shape (128x128 in this case)\n",
    "        gt_mask_resized = np.array([cv2.resize(mask, (pred_mask.shape[1], pred_mask.shape[2]), interpolation=cv2.INTER_LINEAR) for mask in gt_mask_uint8])\n",
    "\n",
    "        # Convert the resized mask back to binary format\n",
    "        gt_mask_resized = gt_mask_resized > 127  # thresholding to get binary mask\n",
    "\n",
    "        # Compute the Dice score or any other metric here\n",
    "        dice = dice_score(pred_mask, gt_mask_resized)\n",
    "        dice_list.append(dice)\n",
    "\n",
    "    # Output the average Dice score\n",
    "    print(f\"Average Dice: {np.mean(dice_list):.4f}\")\n",
    "\n",
    "# Example usage\n",
    "predict_and_evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T17:24:54.361395Z",
     "iopub.status.busy": "2025-04-20T17:24:54.360946Z",
     "iopub.status.idle": "2025-04-20T17:25:37.864516Z",
     "shell.execute_reply": "2025-04-20T17:25:37.862503Z",
     "shell.execute_reply.started": "2025-04-20T17:24:54.361368Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2  # Import OpenCV for resizing\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Define the Dice score function\n",
    "def dice_score(pred, gt):\n",
    "    intersection = np.sum(pred * gt)\n",
    "    return 2.0 * intersection / (np.sum(pred) + np.sum(gt) + 1e-7)\n",
    "\n",
    "# Define the IoU score function\n",
    "def iou_score(pred, gt):\n",
    "    intersection = np.sum(pred * gt)\n",
    "    union = np.sum(pred) + np.sum(gt) - intersection\n",
    "    return intersection / (union + 1e-7)\n",
    "\n",
    "# Define the F1 score function\n",
    "def f_measure(pred, gt, beta=1.0):\n",
    "    intersection = np.sum(pred * gt)\n",
    "    precision = intersection / (np.sum(pred) + 1e-7)\n",
    "    recall = intersection / (np.sum(gt) + 1e-7)\n",
    "    return (1 + beta**2) * (precision * recall) / (beta**2 * precision + recall + 1e-7)\n",
    "\n",
    "# Define the S-measure function (Structural Similarity Measure)\n",
    "def s_measure(pred, gt):\n",
    "    pred_int = pred.astype(np.int32)  # Convert to integers\n",
    "    gt_int = gt.astype(np.int32)      # Convert to integers\n",
    "    return np.sum(np.abs(pred_int - gt_int)) / np.sum(gt_int)\n",
    "\n",
    "# Define the E-measure function (Edge-based Measure)\n",
    "def e_measure(pred, gt):\n",
    "    pred_int = pred.astype(np.int32)  # Convert to integers\n",
    "    gt_int = gt.astype(np.int32)      # Convert to integers\n",
    "    return np.sum(np.abs(pred_int - gt_int)) / (np.sum(np.abs(gt_int)) + 1e-7)\n",
    "\n",
    "# Define the MAE (Mean Absolute Error) function\n",
    "def mae_score(pred, gt):\n",
    "    # Convert boolean arrays to integers (0 or 1)\n",
    "    pred_int = pred.astype(np.int32)\n",
    "    gt_int = gt.astype(np.int32)\n",
    "    return mean_absolute_error(gt_int.flatten(), pred_int.flatten())\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "def predict_and_evaluate(model, val_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    dice_list, iou_list, f1_list, s_list, e_list, mae_list = [], [], [], [], [], []\n",
    "\n",
    "    for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        imgs = batch[\"pixel_values\"].to(device)\n",
    "        gt_masks = batch[\"labels\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(imgs)  # Model returns a SemanticSegmenterOutput\n",
    "            pred_mask = torch.sigmoid(pred.logits).squeeze().cpu().numpy() > 0.5  # Access logits\n",
    "            gt_mask = gt_masks.squeeze().cpu().numpy() > 0.5  # Convert to binary mask\n",
    "\n",
    "        # Convert gt_mask to uint8 for resizing\n",
    "        gt_mask_uint8 = (gt_mask * 255).astype(np.uint8)\n",
    "\n",
    "        # Resize ground truth masks to match the predicted mask shape (128x128 in this case)\n",
    "        gt_mask_resized = np.array([cv2.resize(mask, (pred_mask.shape[1], pred_mask.shape[2]), interpolation=cv2.INTER_LINEAR) for mask in gt_mask_uint8])\n",
    "\n",
    "        # Convert the resized mask back to binary format\n",
    "        gt_mask_resized = gt_mask_resized > 127  # thresholding to get binary mask\n",
    "\n",
    "        # Compute metrics\n",
    "        dice = dice_score(pred_mask, gt_mask_resized)\n",
    "        iou = iou_score(pred_mask, gt_mask_resized)\n",
    "        f1 = f_measure(pred_mask, gt_mask_resized)\n",
    "        s = s_measure(pred_mask, gt_mask_resized)\n",
    "        e = e_measure(pred_mask, gt_mask_resized)\n",
    "        mae = mae_score(pred_mask, gt_mask_resized)\n",
    "\n",
    "        # Append the results for each metric\n",
    "        dice_list.append(dice)\n",
    "        iou_list.append(iou)\n",
    "        f1_list.append(f1)\n",
    "        s_list.append(s)\n",
    "        e_list.append(e)\n",
    "        mae_list.append(mae)\n",
    "\n",
    "    # Output the average of each metric\n",
    "    print(f\"Average Dice: {np.mean(dice_list):.4f}\")\n",
    "    print(f\"Average IoU: {np.mean(iou_list):.4f}\")\n",
    "    print(f\"Average F1 Score: {np.mean(f1_list):.4f}\")\n",
    "    print(f\"Average S Measure: {np.mean(s_list):.4f}\")\n",
    "    print(f\"Average E Measure: {np.mean(e_list):.4f}\")\n",
    "    print(f\"Average MAE: {np.mean(mae_list):.4f}\")\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have the 'val_loader' (data loader for the validation set) and the model loaded\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "predict_and_evaluate(model, val_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T17:26:23.904814Z",
     "iopub.status.busy": "2025-04-20T17:26:23.904458Z",
     "iopub.status.idle": "2025-04-20T17:27:07.428695Z",
     "shell.execute_reply": "2025-04-20T17:27:07.427742Z",
     "shell.execute_reply.started": "2025-04-20T17:26:23.904785Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2  # Import OpenCV for resizing\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Define the Dice score function\n",
    "def dice_score(pred, gt):\n",
    "    intersection = np.sum(pred * gt)\n",
    "    return 2.0 * intersection / (np.sum(pred) + np.sum(gt) + 1e-7)\n",
    "\n",
    "# Define the IoU score function\n",
    "def iou_score(pred, gt):\n",
    "    intersection = np.sum(pred * gt)\n",
    "    union = np.sum(pred) + np.sum(gt) - intersection\n",
    "    return intersection / (union + 1e-7)\n",
    "\n",
    "# Define the F1 score function\n",
    "def f_measure(pred, gt, beta=1.0):\n",
    "    intersection = np.sum(pred * gt)\n",
    "    precision = intersection / (np.sum(pred) + 1e-7)\n",
    "    recall = intersection / (np.sum(gt) + 1e-7)\n",
    "    return (1 + beta**2) * (precision * recall) / (beta**2 * precision + recall + 1e-7)\n",
    "\n",
    "# Define the S-measure function (Structural Similarity Measure)\n",
    "def s_measure(pred, gt):\n",
    "    pred_int = pred.astype(np.int32)  # Convert to integers\n",
    "    gt_int = gt.astype(np.int32)      # Convert to integers\n",
    "    denominator = np.sum(gt_int) + 1e-7  # Add small epsilon to avoid division by zero\n",
    "    return np.sum(np.abs(pred_int - gt_int)) / denominator\n",
    "\n",
    "# Define the E-measure function (Edge-based Measure)\n",
    "def e_measure(pred, gt):\n",
    "    pred_int = pred.astype(np.int32)  # Convert to integers\n",
    "    gt_int = gt.astype(np.int32)      # Convert to integers\n",
    "    denominator = np.sum(np.abs(gt_int)) + 1e-7  # Add small epsilon to avoid division by zero\n",
    "    if denominator == 0:  # If the ground truth is all zeros, return zero for E-measure\n",
    "        return 0\n",
    "    return np.sum(np.abs(pred_int - gt_int)) / denominator\n",
    "\n",
    "# Define the MAE (Mean Absolute Error) function\n",
    "def mae_score(pred, gt):\n",
    "    # Convert boolean arrays to integers (0 or 1)\n",
    "    pred_int = pred.astype(np.int32)\n",
    "    gt_int = gt.astype(np.int32)\n",
    "    return mean_absolute_error(gt_int.flatten(), pred_int.flatten())\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "def predict_and_evaluate(model, val_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    dice_list, iou_list, f1_list, s_list, e_list, mae_list = [], [], [], [], [], []\n",
    "\n",
    "    for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        imgs = batch[\"pixel_values\"].to(device)\n",
    "        gt_masks = batch[\"labels\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(imgs)  # Model returns a SemanticSegmenterOutput\n",
    "            pred_mask = torch.sigmoid(pred.logits).squeeze().cpu().numpy() > 0.5  # Access logits\n",
    "            gt_mask = gt_masks.squeeze().cpu().numpy() > 0.5  # Convert to binary mask\n",
    "\n",
    "        # Convert gt_mask to uint8 for resizing\n",
    "        gt_mask_uint8 = (gt_mask * 255).astype(np.uint8)\n",
    "\n",
    "        # Resize ground truth masks to match the predicted mask shape (128x128 in this case)\n",
    "        gt_mask_resized = np.array([cv2.resize(mask, (pred_mask.shape[1], pred_mask.shape[2]), interpolation=cv2.INTER_LINEAR) for mask in gt_mask_uint8])\n",
    "\n",
    "        # Convert the resized mask back to binary format\n",
    "        gt_mask_resized = gt_mask_resized > 127  # thresholding to get binary mask\n",
    "\n",
    "        # Compute metrics\n",
    "        dice = dice_score(pred_mask, gt_mask_resized)\n",
    "        iou = iou_score(pred_mask, gt_mask_resized)\n",
    "        f1 = f_measure(pred_mask, gt_mask_resized)\n",
    "        s = s_measure(pred_mask, gt_mask_resized)\n",
    "        e = e_measure(pred_mask, gt_mask_resized)\n",
    "        mae = mae_score(pred_mask, gt_mask_resized)\n",
    "\n",
    "        # Append the results for each metric\n",
    "        dice_list.append(dice)\n",
    "        iou_list.append(iou)\n",
    "        f1_list.append(f1)\n",
    "        s_list.append(s)\n",
    "        e_list.append(e)\n",
    "        mae_list.append(mae)\n",
    "\n",
    "    # Output the average of each metric\n",
    "    print(f\"Average Dice: {np.mean(dice_list):.4f}\")\n",
    "    print(f\"Average IoU: {np.mean(iou_list):.4f}\")\n",
    "    print(f\"Average F1 Score: {np.mean(f1_list):.4f}\")\n",
    "    print(f\"Average S Measure: {np.mean(s_list):.4f}\")\n",
    "    print(f\"Average E Measure: {np.mean(e_list):.4f}\")\n",
    "    print(f\"Average MAE: {np.mean(mae_list):.4f}\")\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have the 'val_loader' (data loader for the validation set) and the model loaded\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "predict_and_evaluate(model, val_loader, device)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2932761,
     "sourceId": 5051281,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7202094,
     "sourceId": 11489731,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
